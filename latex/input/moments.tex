\section{The First 4 Moments}
\label{sec:moments}

\subsection{Moments and central moments}

For a random variable $X$, the expectation, also referred to as the first moment, is given by
\begin{align}
    \mu = \mathbb{E}(X)\notag
\end{align}
This expectation is estimated by the sample mean of the observed values $x$:
\begin{align}
    \hat{\mu} = \bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i\notag
\end{align}
Variance serves as a measure of the dispersion of the random variable $X$. In the special case where $\mu = 0$, the variance simplifies to
\begin{align}
    \sigma^2 = \mathbb{E}(X^2)\notag
\end{align}
and is also referred to as the second moment. If $\mu \neq 0$, the variance is defined as
\begin{align}
    \label{eq:definition_variance}
    \sigma^2 &= \mathbb{E}((X-\mu)^2) \\
    &= \mathbb{E}(X^2) - \mathbb{E}(X)^2 \notag
\end{align}
which is also known as the centered second moment. The variance is estimated using
\begin{align}
    \hat{\sigma}^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2\notag
\end{align}
where the denominator $n-1$ represents Bessel's correction, which improves the estimation of variance \cite{radziwillStatisticsEasierWay2017}. Analogously, the $r$-th moment is given by
\begin{align}
    \mathbb{E}(X^r)\notag
\end{align}
and the corresponding centered $r$-th moment is
\begin{align}
    \mathbb{E}((X-\mu)^r)\notag
\end{align}
Skewness measures the asymmetry of a distribution and is defined as the standardized third moment:
\begin{align}
    \label{eq:definition_skewness}
    \gamma_1 &= \frac{\mathbb{E}((X-\mu)^3)}{\sigma^3} \\
    &= \frac{\mathbb{E}(X^3) - 3\mathbb{E}(X)\mathbb{E}(X^2) + 2\mathbb{E}(X)^3}{\sigma^3} \notag
\end{align}
Different methods exist for estimating skewness, such as those proposed by \cite{joanesComparingMeasuresSample1998}:
\begin{align}
    b_1 &= \frac{\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^3}{\left[\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2\right]^{3/2}} \notag \\
    g_1 &= \frac{\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^3}{\left[\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2\right]^{3/2}} \notag \\
    G_1 &= \frac{n^2}{(n-1)(n-2)}b_1 = \frac{\sqrt{n(n-1)}}{n-2}g_1 \notag \\
    \hat{\gamma}_1 &= \frac{n}{(n-1)(n-2)}\sum_{i=1}^n \left(\frac{x_i-\bar{x}}{\hat{\sigma}}\right)^3 \notag
\end{align}
where $b_1$ and $g_1$ are estimators of the population skewness, while $G_1$ and $\hat{\gamma}_1$ estimate the skewness of a sample. The estimator $G_1$ is implemented in statistical software such as Excel, SAS, and SPSS \cite{doaneMeasuringSkewnessForgotten2011}. Kurtosis measures the tailedness of a distribution and is defined as the standardized fourth moment:
\begin{align}
    \label{eq:definition_kurtosis}
    \gamma_2 = \frac{\mathbb{E}((X-\mu)^4)}{\sigma^4} \\
    &= \frac{\mathbb{E}(X^4) - 4\mathbb{E}(X^3)\mathbb{E}(X) + 6\mathbb{E}(X^2)\mathbb{E}(X)^2 - 3\mathbb{E}(X)^4}{\sigma^4} \notag
\end{align}
Various estimation methods for kurtosis exist, such as those presented by \cite{joanesComparingMeasuresSample1998}:
\begin{align}
    g_2 &= \frac{\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^4}{\left[\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2\right]^2} \notag \\
    \hat{\gamma}_2 &= \frac{n(n+1)}{(n-1)(n-2)(n-3)}\sum_{i=1}^n \left(\frac{x_i-\bar{x}}{\hat{\sigma}}\right)^4 \notag
\end{align}
where $g_2$ estimates the kurtosis of a population and $G_2$ estimates the kurtosis of a sample. A commonly used alternative is excess kurtosis, which is obtained by subtracting 3:
\begin{align}
    \gamma_2^* &= \gamma_2 - 3\notag \\
    G_2 &= \frac{n-1}{(n-2)(n-3)}[(n+1)g_2 + 6] \notag
\end{align}
This adjustment is motivated by the fact that for a standard normally distributed variable $X$, the kurtosis is $\gamma_2 = 3$ and the excess kurtosis is $\gamma_2^* = 0$. In general, due to the high powers involved in the definitions of skewness and kurtosis, these estimators are highly sensitive to outliers. In the following, the term moments will be used broadly to include related measures such as variance, skewness, and kurtosis.

\subsection{Cumulants}

Throughout this work, the concept of cumulants will also be used, which provide an alternative representation of moments. The $r$-th cumulant is defined as the coefficient of $t^r$ in the logarithm of the moment generating function of $X$. The moment generating function of $X$ is given by
\begin{align}
    M_X(t) = \mathbb{E}(e^{tX})\notag
\end{align}
The cumulant generating function of $X$ is then defined as
\begin{align}
    K_X(t) = \log(M_X(t))\notag
\end{align} 
From this definition, the first four cumulants are given by
\begin{align}
    \label{eq:cumulants_1}
    \kappa_1 &= \mu\\
    \label{eq:cumulants_2}
    \kappa_2 &= \sigma^2\\
    \label{eq:cumulants_3}
    \kappa_3 &= \gamma_1\sigma^3\\
    \label{eq:cumulants_4}
    \kappa_4 &= \gamma_2^*\sigma^4
\end{align}

\subsection{Estimating the Moments of Low-Frequency Data using High-Frequency Data}
For the pricing of financial derivatives, it is crucial to know the moments of returns, particularly those of monthly or quarterly returns \cite{barroRareDisastersAsset2006}. However, estimating the moments of such low-frequency returns can be challenging due to the limited number of observations available \cite{neubergerSkewnessStockMarket2021}. Today, financial markets operate continuously, making it possible to obtain daily or even minute-level returns without difficulty. For example, the German stock index DAX is calculated every second \cite{boersefrankfurtFunktioniertBoerse}. There are several approaches to estimating the moments of monthly or quarterly returns based on the moments of daily returns. One such method is proposed by \cite{amayaDoesRealizedSkewness2015}. In this approach, the $i$-th intraday log return $r_{t,i}$ for day $t$ is computed as
\begin{align}
    r_{t,i} = \log(P_{t,i/N}) - \log(P_{t,(i-1)/N})\notag
\end{align}
where $p$ represents the natural logarithm of the price, and $N$ denotes the number of return observations within a trading day. The opening log-price on day $t$ is given by $p_{t,0}$, while the closing log-price is $p_{t,1}$. Using five-minute returns, a standard 6.5-hour trading session results in $N = 78$. Based on this, the daily realized variance is computed as
\begin{align}
    \hat{\sigma}^2_t = \sum_{i=1}^{N}r_{t,i}^2\notag
\end{align}
This idea is not new and was first introduced by \cite{andersenAnsweringSkepticsYes1998}. Building upon this approach, the daily realized skewness and kurtosis can be computed as
\begin{align}
    \hat{\gamma}_1 = \frac{\sqrt{N}\cdot \sum_{i=1}^{N}r_{t,i}^3}{\hat{\sigma}_t^3}\notag\\
    \hat{\gamma}_2 = \frac{N\cdot \sum_{i=1}^{N}r_{t,i}^4}{\hat{\sigma}_t^4}\notag
\end{align}
To transition from daily realized moments to weekly or monthly moments, a moving average approach is applied. \cite{choeHighMomentVariations2014} use variation processes to estimate low-frequency moments, specifically the quadratic variation of a semimartingale $X$:
\begin{align}
    \label{eq:quadratic_variation}
    [X]_t = X_t^2 - 2\int_0^tX_u\,\mathrm{d}X_u
\end{align}
and the quadratic covariation process of two semimartingales $X$ and $Y$:
\begin{align}
    \label{eq:quadratic_covariation}
    [X,Y]_t = X_tY_t - \int_0^tX_u\,\mathrm{d}Y_u - \int_0^tY_u\,\mathrm{d}X_u
\end{align}
For the log-return process $R_t$,
\begin{align}
    R_t = \log(P_t) - \log(P_0)\notag
\end{align}
equations \eqref{eq:quadratic_variation} and \eqref{eq:quadratic_covariation} can be approximated as follows:
\begin{align}
    [R]_T &\approx \sum_{i=1}^N (R_i - R_{i-1})^2\notag\\
    [R,R^2]_T &\approx \sum_{i=1}^N (R_i - R_{i-1})(R_i^2 - R_{i-1}^2)\notag \\
    [R^2]_T &\approx \sum_{i=1}^N (R_i^2 - R_{i-1}^2)^2\notag
\end{align}
From these, the moments follow:
\begin{align}
    \mathbb{E}(R_T^3) = \frac{3}{2}\mathbb{E}([R,R^2]_T)\notag\\
    \mathbb{E}(R_T^4) = \frac{3}{2}\mathbb{E}([R^2]_T)\notag
\end{align}
The estimation of low-frequency variance follows the same approach as \cite{andersenAnsweringSkepticsYes1998} and \cite{amayaDoesRealizedSkewness2015}. \cite{neubergerSkewnessStockMarket2021} propose a novel method that only requires log prices to be martingales and stationary, meaning there is no drift. Under these conditions, they define new moment measures that approximate the standard definitions:
\begin{align}
    var^L(r) &= \mathbb{E}(x^{(2L)}(r))\text{, where } x^{(2L)}(r) = 2(e^r-1-r) \notag \\
    var^E(r) &= \mathbb{E}(x^{(2E)}(r))\text{, where } x^{(2E)}(r) = 2(re^r-e^r+1) \notag \\
    skew(r) &= \frac{\mathbb{E}(x^{(3)}(r))}{var^L(r)^{3/2}}\text{, where } x^{(3)}(r) = 6((e^r+1)r - 2(e^r-1)) \notag \\
    kurt(r) &= \frac{\mathbb{E}(x^{(4)}(r))}{var^L(r)^2}\text{, where } x^{(4)}(r) = 12(r^2 + 2(e^r+2)r - 6(e^r-1)) \notag
\end{align}
where $r$ represents the log-return process:
\begin{align}
    r_t = \ln\left(\frac{P_t}{P_{t-1}}\right) \notag
\end{align}
The long-horizon returns process $R$ is defined as
\begin{align}
    R_t(T) &= \ln\left(\frac{P_t}{P_{t-T}}\right) \notag
\end{align}
This establishes a connection between low-frequency moments and high-frequency log returns:
\begin{align}
    var^L(R(T)) &= T\cdot var^L(r) \notag \\
    skew(R(T)) &= \left(skew(r) + 3\frac{cov(y^{(1)}, x^{(2E)}(r))}{var^L(r)^{3/2}}\right)T^{-1/2} \notag \\
    kurt(R(T)) &= \left(kurt(r) + 4\frac{cov(y^{(1)}, x^{(3)}(r))}{var^L(r)^2} + 6\frac{cov(y^{(2L)}, x^{(2L)}(r))}{var^L(r)^2}\right)T^{-1} \notag
\end{align}
where
\begin{align}
    y_t^{(j)} &= \sum_{u=1}^T \frac{x^{(j)}(R_{t-1}(u))}{T} \quad\text{for } j = 1,2L\notag \\
    \label{eq:x1}
    x^{(1)} &= e^r-1
\end{align}
where equation \eqref{eq:x1} originates from \cite{neubergerRealizedSkewness2012}. In \cite{neubergerRealizedSkewness2012}, the aggregation property is also introduced: if $g$ is a real function, $X$ is a process, and for times $0\le s\le t\le u\le T$,
\begin{align}
    \mathbb{E}_s(g(X_u-X_s)) = \mathbb{E}_s(g(X_u-X_t)) + \mathbb{E}_t(g(X_t-X_s))\notag
\end{align}
then the pair $(g,X)$ satisfies the aggregation property. This property is used, for instance, in estimating low-frequency variance by summing high-frequency variance. \cite{fukasawaRealizedCumulantsMartingales2021} build on this idea and derive formulas for realized cumulants that also satisfy the aggregation property.

\subsection{The First 4 Moments of the Heston Model}

Care must be taken with notation, as symbols such as $\mu$ and $\sigma$ previously denoted the mean and variance but are now used to represent the drift and volatility of the Heston model (see Equations \eqref{eq:heston_model_price} and \eqref{eq:heston_model_variance}). The noncentral moments are denoted by $\mu_1$ through $\mu_4$, while the central and standardized moments are denoted by $\zeta_1$ through $\zeta_4$.

Fortunately, moments for returns and other related measures have been derived. \cite{okhrinSimulatingCoxIngersoll2022} provide the unconditional noncentral moments for the log-return $r_t = \log(S_t) - \log(S_0)$:
\begin{align}
    \mu_1 &= \left(\mu - \frac{\theta}{2}\right)t\notag \\
    \mu_2 &= \frac{1}{4\kappa^3}\left(\exp(-\kappa t)\left[\exp(\kappa t)\left\lbrace\kappa^3 t(t(\theta-2\mu)^2 + 4\theta) - 4\kappa^2\rho\sigma t\theta + \kappa\sigma\theta(4\rho + \sigma t) - \sigma^2\theta\right\rbrace + \sigma\theta(\sigma-4\kappa\rho)\right]\right) \notag
\end{align}
The expressions for $\mu_3$ and $\mu_4$ are too lengthy to be included here but can be found in \cite{okhrinSimulatingCoxIngersoll2022}. The corresponding unconditional central and standardized moments are then given by:
\begin{align}
    \zeta_1 &= \mu_1\notag \\
    \zeta_2 &= \mathbb{E}\left[(r_t-\mu_1)^2\right] \notag \\
    &= \frac{\theta[-4\kappa^2\rho\sigma t + 4\kappa^3 t + \sigma\exp(-\kappa t)(\sigma - 4\kappa\rho) + 4\kappa\sigma\rho + \kappa\sigma^2 t - \sigma^2]}{4\kappa^3} \notag \\
    \zeta_3 &= \mathbb{E}\left[\left(\frac{r_t-\mu_1}{\zeta_1^{1/2}}\right)^3\right] \notag \\
    &= \frac{3\kappa\sigma\theta\exp(\kappa t/2)(\sigma - 2\kappa\rho)}{\zeta_2^{3/2}}[4\kappa^2\{\exp(\kappa t)(\rho\sigma t+1) + \rho\sigma t - 1\} - 4\kappa^3 t\exp(\kappa t) - \kappa\sigma\{\exp(\kappa t)(8\rho + \sigma t) - 8\rho + \sigma t\} + 2\sigma^2(\exp(\kappa t)-1)] \notag \\
    \zeta_4 &= \mathbb{E}\left[\left(\frac{r_t-\mu_1}{\zeta_1^{1/2}}\right)^4\right] \notag
\end{align}
The expression for $\zeta_4$ is omitted here but can be found in \cite{okhrinSimulatingCoxIngersoll2022}.

\cite{zhaoRelationPhysicalRiskneutral2013} and \cite{zhangSkewnessImpliedHeston2017} analyze moments for the continuously compounded return $R_t^T = \ln\left(\frac{S_T}{S_t}\right)$ and derive the conditional central variance:
\begin{align}
    \mathbb{E}_t(R_t^T-\mathbb{E}_t(R_t^T))^2 = \frac{1}{4}\text{Var}_t(\int_t ^T v_s\,\mathrm{d}s) + SW_{t,T} - \mathbb{E}_t(\int_t^T \sqrt{v_s}\,\mathrm{d}B_s(\int_t^T v_s\,\mathrm{d}s-\mathbb{E}_t(\int_t^T v_s\,\mathrm{d}s)))
\end{align}
where $v_t$ represents the variance at time $t$, $SW$ is the variance swap rate (the expectation of realized variance), and $B_t$ is a Brownian motion. \cite{zhangSkewnessImpliedHeston2017} further elaborate:
\begin{align}
    \mathbb{E}_t(R_t^T-\mathbb{E}_t(R_t^T))^2 &= \int_t^T \mathbb{E}_t(v_s)\,\mathrm{d}s - \rho\sigma\int_t^T \frac{1-\exp(-\kappa(T-s))}{\kappa}\mathbb{E}_t(v_s)\,\mathrm{d}s + \frac{1}{4}\left(\sigma^2\int_t^T\frac{(1-\exp(-\kappa(T-s)))^2}{\kappa^2}\mathbb{E}_t(v_s) \,\mathrm{d}s\right) \notag
\end{align}
Using the expected instantaneous variance $\mathbb{E}_t(v_s) = \theta + (v_t - \theta)\exp(-\kappa(s-t))$, Mathematica yields the following results:
\begin{align}
    \int_t^T\mathbb{E}_t(V_s)\,\mathrm{d}s &= \frac{v_t - \theta + \exp(\kappa(t-T))(-v_t+\theta) - t \theta\kappa + T\theta\kappa}{\kappa} \notag \\
    \rho\sigma\int_t^T \frac{1-\exp(-\kappa(T-s))}{\kappa}\mathbb{E}_t(v_s)\,\mathrm{d}s &= \frac{\exp(-T\kappa)[\exp(t\kappa)(-v_t+2\theta+(t-T)(v_t-\theta)\kappa) + \exp(T\kappa)(v_t+\theta(-2-t\kappa + T\kappa))]\rho\sigma}{\kappa^2} \notag \\
    \sigma^2\int_t^T\frac{(1-\exp(-\kappa(T-s)))^2}{\kappa^2}\mathbb{E}_t(v_s) \,\mathrm{d}s &= \frac{\exp(-2T\kappa)(\exp(2t\kappa)(-2v_t+\theta) + 4\exp((t+T)\kappa)(\theta + (t-T)(v_t-\theta)\kappa) + \exp(2T\kappa)(2v_t + \theta(-5-2t\kappa + 2T\kappa)))\sigma^2}{2\kappa^3} \notag
\end{align}
The third conditional central moment is given by
\begin{align}
    \mathbb{E}_t(R_t^T-\mathbb{E}_t(R_t^T))^3 &= \mathbb{E}_t(X_T^3) - \frac{3}{2}\mathbb{E}_t(X_T^2Y_T) + \frac{3}{4}\mathbb{E}_t(X_TY_T^2) - \frac{1}{8}\mathbb{E}_t(Y_T^3) \notag
\end{align}
where $X_T$ and $Y_T$ are defined as
\begin{align}
    X_T &= \int_t^T \sqrt{v_s}\,\mathrm{d}B_s^S \notag \\
    Y_T &= \int_t^T (v_s - \mathbb{E}_t(v_s))\,\mathrm{d}s = \sigma\int_t^T\frac{1-\exp(-\kappa(T-s))}{\kappa}\sqrt{v_s}\,\mathrm{d}B_s^v \notag
\end{align}
where $B^S$ and $B^v$ are the Brownian motions associated with price and volatility, respectively.

\cite{dunnEstimatingOptionPrices2014} derive the unconditional noncentral moments for the return $Q_{t+1}=\frac{S_{t+1}}{S_t}$:
\begin{align}
    \mathbb{E}(Q_{t+1}) &= \mu_1 = 1+\mu  \notag \\
    \mathbb{E}(Q_{t+1}^2) &= \mu_2 = (\mu +1)^2+\theta \notag \\
    \mathbb{E}(Q_{t+1}^3) &= \mu_3 = (\mu +1)^3+3\theta+3\mu\theta \notag \\
    \mathbb{E}(Q_{t+1}^4) &= \mu_4 = \frac{1}{\kappa (\kappa -2)}(\kappa^2\mu^4 + 4\kappa^2\mu^3 + 6\kappa^2\mu^2\theta - 2\kappa\mu^4 + 6\kappa^2\mu^2 + 12\kappa^2\mu\theta + 3\kappa^2\theta^2 - 8\kappa\mu^3 - 12\kappa\mu^2\theta + 4\kappa^2\mu + 6\kappa^2\theta - 12\kappa\mu^2 - 24\kappa\mu\theta - 6\kappa\theta^2 - 3\sigma^2\theta + \kappa^2 - 8\kappa\mu - 12\kappa\theta - 2\kappa) \notag
\end{align}
Using Equations \eqref{eq:definition_variance}, \eqref{eq:definition_skewness}, and \eqref{eq:definition_kurtosis}, the central and standardized moments follow as
\begin{align}
    \zeta_1 &= 1+\mu \notag \\
    \zeta_2 &= \theta \notag \\
    \zeta_3 &= 0 \notag \\
    \zeta_4 &= 3\frac{\kappa^2\theta - 2\kappa\theta - \sigma^2}{\kappa\theta(\kappa-2)} \notag
\end{align}